{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 34
            },
            "colab_type": "code",
            "id": "HyafYO0Y4fV5",
            "outputId": "430c9863-ece2-43af-d4df-f11ace1389bb"
         },
         "outputs": [],
         "source": [
            "#Mount Drive\n",
            "from google.colab import drive\n",
            "drive.mount('/content/drive')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 1000
            },
            "colab_type": "code",
            "id": "LUTqBDtN4nBZ",
            "outputId": "725f6f1d-c097-4eda-bbf4-5b14384d3169"
         },
         "outputs": [],
         "source": [
            "#Restart runtime after running once\n",
            "\n",
            "%pip install segmentation-models-pytorch==0.1.0\n",
            "%pip install -U catalyst"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 221
            },
            "colab_type": "code",
            "id": "RTIa2pt242KC",
            "outputId": "0c73d427-e98a-405d-be6f-5484ef14ae73"
         },
         "outputs": [],
         "source": [
            "#Dependencies\n",
            "\n",
            "#Handles data \n",
            "import json\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "import cv2\n",
            "import glob\n",
            "from operator import itemgetter\n",
            "import pickle\n",
            "\n",
            "#Torch utilities \n",
            "from typing import List\n",
            "from pathlib import Path\n",
            "from torch.utils.data import Dataset\n",
            "import torch\n",
            "\n",
            "#Data Loader utilities \n",
            "import collections\n",
            "from sklearn.model_selection import train_test_split\n",
            "from torch.utils.data import DataLoader\n",
            "\n",
            "#Model building and training \n",
            "import segmentation_models_pytorch as smp\n",
            "from torch import nn\n",
            "\n",
            "from catalyst.contrib.nn import DiceLoss, IoULoss\n",
            "from torch import optim\n",
            "from torch.optim import AdamW\n",
            "from catalyst import utils\n",
            "\n",
            "from catalyst.contrib.nn import RAdam, Lookahead\n",
            "from catalyst.dl import SupervisedRunner\n",
            "\n",
            "from catalyst.dl.callbacks import DiceCallback, IouCallback, \\\n",
            "  CriterionCallback, AccuracyCallback, MulticlassDiceMetricCallback"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 153
            },
            "colab_type": "code",
            "id": "ZZMn19YZ461B",
            "outputId": "c1578e1c-4a20-40ef-bad8-5e6a047a9257"
         },
         "outputs": [],
         "source": [
            "#Set seed for better reproducibility \n",
            "SEED = 42\n",
            "utils.set_global_seed(SEED)\n",
            "utils.prepare_cudnn(deterministic=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {},
            "colab_type": "code",
            "id": "Db-Rc7QI5ILD"
         },
         "outputs": [],
         "source": [
            "#Define and establish a dataset class\n",
            "class SegmentationDataset(Dataset): \n",
            "    def __init__(\n",
            "        self,\n",
            "        image_arr_path,\n",
            "        mask_arr_path,\n",
            "    ) -> None:\n",
            "        self.images = np.load(image_arr_path)\n",
            "        self.masks = np.load(mask_arr_path)\n",
            "\n",
            "    def __len__(self) -> int:\n",
            "        return len(self.images)\n",
            "\n",
            "    def __getitem__(self, idx: int) -> dict:\n",
            "        image = self.images[idx]\n",
            "        image = np.swapaxes(image, 2, 0)\n",
            "        image = np.swapaxes(image, 2, 1)\n",
            "        image = torch.from_numpy(image).float()\n",
            "        result = {\"image\": image}\n",
            "        \n",
            "        if self.masks is not None:\n",
            "            mask = self.masks[idx]\n",
            "            mask = np.swapaxes(mask, 2, 0)\n",
            "            mask = np.swapaxes(mask, 2, 1)\n",
            "            mask = torch.from_numpy(mask).float()\n",
            "            result[\"mask\"] = mask\n",
            "        return result"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {},
            "colab_type": "code",
            "id": "dhNonDYC5Mn3"
         },
         "outputs": [],
         "source": [
            "#Load dataset once to enable visualizion prior to model training \n",
            "dset = SegmentationDataset(image_arr_path=\"/content/drive/Shared drives/Allan add details\", \n",
            "                           mask_arr_path=\"/content/drive/Shared drives/Allan add details\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 34
            },
            "colab_type": "code",
            "id": "rImIgzH18SQG",
            "outputId": "7ab4ba88-612c-40ee-a2af-e2ccf31ded0a"
         },
         "outputs": [],
         "source": [
            "#Show sizes of the image and mask \n",
            "out = dset[0]\n",
            "out[\"image\"].shape, out[\"mask\"].shape, len(dset)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 286
            },
            "colab_type": "code",
            "id": "YRx-KKFi8U0X",
            "outputId": "2a0fe7aa-08bd-4e29-87aa-fdbb55444cda"
         },
         "outputs": [],
         "source": [
            "#Show an image \n",
            "image = np.asarray(dset[40]['image'])\n",
            "image = np.swapaxes(image, 2, 0)\n",
            "image = np.swapaxes(image, 1, 0)\n",
            "image = image.astype(np.uint8)\n",
            "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 286
            },
            "colab_type": "code",
            "id": "BystD5Kn8xcS",
            "outputId": "9384e9dd-3182-494c-91f2-38b32122ed31"
         },
         "outputs": [],
         "source": [
            "#Show associated mask \n",
            "mask = np.squeeze(dset[40]['mask'])\n",
            "plt.imshow(mask)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {},
            "colab_type": "code",
            "id": "PULH56AV80DU"
         },
         "outputs": [],
         "source": [
            "#Set up U-Net with EfficientNet backbone pretrained on ImageNet\n",
            "\t\n",
            "ENCODER = 'efficientnet-b3'\n",
            "ENCODER_WEIGHTS = 'imagenet'\n",
            "DEVICE = 'cuda'\n",
            "ACTIVATION = None\n",
            "\n",
            "model = smp.Unet(\n",
            "    encoder_name=ENCODER, \n",
            "    encoder_weights=ENCODER_WEIGHTS, \n",
            "    classes=3, \n",
            "    activation=ACTIVATION,\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {},
            "colab_type": "code",
            "id": "WIfyQYAhY26C"
         },
         "outputs": [],
         "source": [
            "#Define loaders \n",
            "\n",
            "def get_loaders(\n",
            "    images: List[Path],\n",
            "    masks: List[Path],\n",
            "    image_arr_path: str,\n",
            "    mask_arr_path: str,\n",
            "    random_state: int,\n",
            "    valid_size: float = 0.1,\n",
            "    batch_size: int = 12,\n",
            "    num_workers: int = 4,\n",
            "    ) -> dict:\n",
            "\n",
            "    indices = np.arange(len(images))\n",
            "\n",
            "    train_indices, valid_indices = train_test_split(\n",
            "      indices, test_size=valid_size, random_state=random_state, shuffle=True\n",
            "    )\n",
            "\n",
            "    np_images = np.array(images)\n",
            "    np_masks = np.array(masks)\n",
            "\n",
            "\n",
            "    train_dataset = SegmentationDataset(image_arr_path, mask_arr_path)\n",
            "    train_dataset.images = np_images[train_indices]\n",
            "    train_dataset.masks = np_masks[train_indices]\n",
            "\n",
            "    valid_dataset = SegmentationDataset(image_arr_path, mask_arr_path)\n",
            "    valid_dataset.images = np_images[valid_indices]\n",
            "    valid_dataset.masks = np_masks[valid_indices]\n",
            "\n",
            "    train_loader = DataLoader(\n",
            "      train_dataset,\n",
            "      batch_size=batch_size,\n",
            "      shuffle=False,\n",
            "      num_workers=num_workers,\n",
            "      drop_last=False,\n",
            "    )\n",
            "\n",
            "    valid_loader = DataLoader(\n",
            "      valid_dataset,\n",
            "      batch_size=batch_size,\n",
            "      shuffle=False,\n",
            "      num_workers=num_workers,\n",
            "      drop_last=False,\n",
            "    )\n",
            "\n",
            "    loaders = collections.OrderedDict()\n",
            "    loaders[\"train\"] = train_loader\n",
            "    loaders[\"valid\"] = valid_loader\n",
            "\n",
            "    return loaders"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {},
            "colab_type": "code",
            "id": "g0woYVfD9JJV"
         },
         "outputs": [],
         "source": [
            "#Get loaders  \n",
            "\n",
            "loaders = get_loaders(\n",
            "    images=np.load(\"/content/drive/Shared drives/Allan add details\"),\n",
            "    masks=np.load(\"/content/drive/Shared drives/Allan add details\"),\n",
            "    image_arr_path=\"/content/drive/Shared drives/Allan add details\",\n",
            "    mask_arr_path=\"/content/drive/Shared drives/Allan add details\",\n",
            "    random_state=420,\n",
            "    valid_size=0.1,\n",
            "    batch_size=3,\n",
            "    num_workers=2,\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {},
            "colab_type": "code",
            "id": "B68HPeDESWlo"
         },
         "outputs": [],
         "source": [
            "#    Helpful code taken from Joseph Chen \n",
            "#\n",
            "#    Copyright 2019 Division of Medical Image Computing, German Cancer Research Center (DKFZ), Heidelberg, Germany\n",
            "#\n",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "#    you may not use this file except in compliance with the License.\n",
            "#    You may obtain a copy of the License at\n",
            "#\n",
            "#        http://www.apache.org/licenses/LICENSE-2.0\n",
            "#\n",
            "#    Unless required by applicable law or agreed to in writing, software\n",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "#    See the License for the specific language governing permissions and\n",
            "#    limitations under the License.\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "import numpy as np\n",
            "\n",
            "def sum_tensor(inp, axes, keepdim=False):\n",
            "    axes = np.unique(axes).astype(int)\n",
            "    if keepdim:\n",
            "        for ax in axes:\n",
            "            inp = inp.sum(int(ax), keepdim=True)\n",
            "    else:\n",
            "        for ax in sorted(axes, reverse=True):\n",
            "            inp = inp.sum(int(ax))\n",
            "    return inp\n",
            "\n",
            "def softmax_helper(x):\n",
            "    rpt = [1 for _ in range(len(x.size()))]\n",
            "    rpt[1] = x.size(1)\n",
            "    x_max = x.max(1, keepdim=True)[0].repeat(*rpt)\n",
            "    e_x = torch.exp(x - x_max)\n",
            "    return e_x / e_x.sum(1, keepdim=True).repeat(*rpt)\n",
            "\n",
            "class CrossentropyND(nn.CrossEntropyLoss):\n",
            "    \"\"\"\n",
            "    Network has to have NO NONLINEARITY!\n",
            "    \"\"\"\n",
            "    def forward(self, inp, target):\n",
            "        target = target.long()\n",
            "        num_classes = inp.size()[1]\n",
            "\n",
            "        i0 = 1\n",
            "        i1 = 2\n",
            "\n",
            "        while i1 < len(inp.shape): \n",
            "            inp = inp.transpose(i0, i1)\n",
            "            i0 += 1\n",
            "            i1 += 1\n",
            "\n",
            "        inp = inp.contiguous()\n",
            "        inp = inp.view(-1, num_classes)\n",
            "\n",
            "        target = target.view(-1,)\n",
            "\n",
            "        return super(CrossentropyND, self).forward(inp, target)\n",
            "\n",
            "def get_tp_fp_fn(net_output, gt, axes=None, mask=None, square=False):\n",
            "    \"\"\"\n",
            "    net_output must be (b, c, x, y(, z)))\n",
            "    gt must be a label map (shape (b, 1, x, y(, z)) OR shape (b, x, y(, z))) or one hot encoding (b, c, x, y(, z))\n",
            "    if mask is provided it must have shape (b, 1, x, y(, z)))\n",
            "    :param net_output:\n",
            "    :param gt:\n",
            "    :param axes:\n",
            "    :param mask: mask must be 1 for valid pixels and 0 for invalid pixels\n",
            "    :param square: if True then fp, tp and fn will be squared before summation\n",
            "    :return:\n",
            "    \"\"\"\n",
            "    if axes is None:\n",
            "        axes = tuple(range(2, len(net_output.size())))\n",
            "\n",
            "    shp_x = net_output.shape\n",
            "    shp_y = gt.shape\n",
            "\n",
            "    with torch.no_grad():\n",
            "        if len(shp_x) != len(shp_y):\n",
            "            gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n",
            "\n",
            "        if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n",
            "            # if this is the case then gt is probably already a one hot encoding\n",
            "            y_onehot = gt\n",
            "        else:\n",
            "            gt = gt.long()\n",
            "            y_onehot = torch.zeros(shp_x)\n",
            "            if net_output.device.type == \"cuda\":\n",
            "                y_onehot = y_onehot.cuda(net_output.device.index)\n",
            "            y_onehot.scatter_(1, gt, 1)\n",
            "\n",
            "    tp = net_output * y_onehot\n",
            "    fp = net_output * (1 - y_onehot)\n",
            "    fn = (1 - net_output) * y_onehot\n",
            "\n",
            "    if mask is not None:\n",
            "        tp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(tp, dim=1)), dim=1)\n",
            "        fp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fp, dim=1)), dim=1)\n",
            "        fn = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fn, dim=1)), dim=1)\n",
            "\n",
            "    if square:\n",
            "        tp = tp ** 2\n",
            "        fp = fp ** 2\n",
            "        fn = fn ** 2\n",
            "\n",
            "    tp = sum_tensor(tp, axes, keepdim=False)\n",
            "    fp = sum_tensor(fp, axes, keepdim=False)\n",
            "    fn = sum_tensor(fn, axes, keepdim=False)\n",
            "\n",
            "    return tp, fp, fn\n",
            "\n",
            "\n",
            "class SoftDiceLoss(nn.Module):\n",
            "    def __init__(self, apply_nonlin=None, batch_dice=False, do_bg=True,\n",
            "                 smooth=1., square=False):\n",
            "        super(SoftDiceLoss, self).__init__()\n",
            "\n",
            "        self.square = square\n",
            "        self.do_bg = do_bg\n",
            "        self.batch_dice = batch_dice\n",
            "        self.apply_nonlin = apply_nonlin\n",
            "        self.smooth = smooth\n",
            "\n",
            "    def forward(self, x, y, loss_mask=None):\n",
            "        shp_x = x.shape\n",
            "\n",
            "        if self.batch_dice:\n",
            "            axes = [0] + list(range(2, len(shp_x)))\n",
            "        else:\n",
            "            axes = list(range(2, len(shp_x)))\n",
            "\n",
            "        if self.apply_nonlin is not None:\n",
            "            x = self.apply_nonlin(x)\n",
            "\n",
            "        tp, fp, fn = get_tp_fp_fn(x, y, axes, loss_mask, self.square)\n",
            "\n",
            "        dc = (2 * tp + self.smooth) / (2 * tp + fp + fn + self.smooth)\n",
            "\n",
            "        if not self.do_bg:\n",
            "            if self.batch_dice:\n",
            "                dc = dc[1:]\n",
            "            else:\n",
            "                dc = dc[:, 1:]\n",
            "        dc = dc.mean()\n",
            "\n",
            "        return -dc\n",
            "\n",
            "\n",
            "class DC_and_CE_loss(nn.Module):\n",
            "    def __init__(self, soft_dice_kwargs, ce_kwargs, aggregate=\"sum\"):\n",
            "        super(DC_and_CE_loss, self).__init__()\n",
            "        self.aggregate = aggregate\n",
            "        self.ce = CrossentropyND(**ce_kwargs)\n",
            "        self.dc = SoftDiceLoss(apply_nonlin=softmax_helper, **soft_dice_kwargs)\n",
            "\n",
            "    def forward(self, net_output, target):\n",
            "        dc_loss = self.dc(net_output, target)\n",
            "        ce_loss = self.ce(net_output, target)\n",
            "        if self.aggregate == \"sum\":\n",
            "            result = ce_loss + dc_loss\n",
            "        else:\n",
            "            raise NotImplementedError(\"did not work\") \n",
            "        return result"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {},
            "colab_type": "code",
            "id": "Eslu8HbO9cn1"
         },
         "outputs": [],
         "source": [
            "#Define loss criterion\n",
            "criterion = {\n",
            "    \"CE\": CrossentropyND(),\n",
            "}\n",
            "\n",
            "#Configure model optimization \n",
            "learning_rate = 0.001 \n",
            "encoder_learning_rate = 0.0005\n",
            "encoder_weight_decay = 0.00003 \n",
            "optimizer_weight_decay = 0.0003 \n",
            "optim_factor = 0.25\n",
            "optim_patience = 2 \n",
            "\n",
            "optimizer = AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
            "\n",
            "#Use scheduler for improved results\n",
            "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=optim_factor, patience=optim_patience)\n",
            "\n",
            "num_epochs = 10\n",
            "device = utils.get_device()\n",
            "\n",
            "runner = SupervisedRunner(device=device, input_key=\"image\", input_target_key=\"mask\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {},
            "colab_type": "code",
            "id": "WbHr5cLs9jNV"
         },
         "outputs": [],
         "source": [
            "#Establish calculations during training through Catalyst callbacks\n",
            "callbacks = [\n",
            "        CriterionCallback(\n",
            "            input_key=\"mask\",\n",
            "            prefix=\"loss\",\n",
            "            criterion_key=\"CE\"\n",
            "        ),\n",
            "        MulticlassDiceMetricCallback(input_key=\"mask\")\n",
            "        ]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 1000
            },
            "colab_type": "code",
            "id": "VU1-WO_j9l-H",
            "outputId": "588120b5-30ca-4270-fc99-21e76bee2916"
         },
         "outputs": [],
         "source": [
            "#Run training loop\n",
            "runner.train(\n",
            "    model=model,\n",
            "    criterion=criterion,\n",
            "    optimizer=optimizer,\n",
            "    scheduler=scheduler,\n",
            "    loaders=loaders,\n",
            "    callbacks=callbacks,\n",
            "    logdir='content/full_model2', #this logdir must be changed with every new run\n",
            "    num_epochs=num_epochs,\n",
            "    main_metric=\"loss\",\n",
            "    minimize_metric=True,\n",
            "    fp16=None,    \n",
            "    verbose=True,\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {},
            "colab_type": "code",
            "id": "5qUJrvvfGBuX"
         },
         "outputs": [],
         "source": [
            "#Test model on test dataset\n",
            "test_data = SegmentationDataset(\"/content/drive/Shared drives/Allan add details\", \n",
            "                                \"/content/drive/Shared drives/Allan add details\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {},
            "colab_type": "code",
            "id": "WKVTQwezDV8I"
         },
         "outputs": [],
         "source": [
            "#Create loader for predictions\n",
            "infer_loader = DataLoader(\n",
            "    test_data,\n",
            "    batch_size=12,\n",
            "    shuffle=False,\n",
            "    num_workers=4\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 51
            },
            "colab_type": "code",
            "id": "kUlJfoyvJQDo",
            "outputId": "ab0d35e0-cad8-4b53-8005-db0ec94a657a"
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "<class 'numpy.ndarray'>\n",
                  "(149, 3, 480, 640)\n"
               ]
            }
         ],
         "source": [
            "#Get model predictions on test dataset\n",
            "predictions = np.vstack(list(map(\n",
            "    lambda x: x[\"logits\"].cpu().numpy(), \n",
            "    runner.predict_loader(loader=infer_loader, resume=f\"content/full_model2/checkpoints/best.pth\")\n",
            ")))\n",
            "\n",
            "print(type(predictions))\n",
            "print(predictions.shape)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 1000
            },
            "colab_type": "code",
            "id": "EjYsnN9vysZr",
            "outputId": "e1211bce-1eac-4603-d95b-19dec90a8198"
         },
         "outputs": [],
         "source": [
            "#Display sample prediction results \n",
            "\n",
            "pred_results = {}\n",
            "rand_nums = np.random.randint(low=1, high=148, size=18)\n",
            "rand_nums = np.insert(rand_nums, 0, 30)\n",
            "rand_nums = np.insert(rand_nums, 0, 141)\n",
            "\n",
            "for num in rand_nums:\n",
            "\n",
            "    #Show image\n",
            "    image = np.asarray(test_data[num]['image'])\n",
            "    image = np.swapaxes(image, 2, 0)\n",
            "    image = np.swapaxes(image, 1, 0)\n",
            "    image = image.astype(np.uint8)\n",
            "\n",
            "\n",
            "    #Show mask\n",
            "    mask = np.squeeze(test_data[num]['mask'])\n",
            "\n",
            "    #Show predicted mask\n",
            "    pred_mask = np.asarray(predictions[num])\n",
            "    pred_mask = np.swapaxes(pred_mask, 2, 0)\n",
            "    pred_mask = np.swapaxes(pred_mask, 1, 0)\n",
            "    pred_mask = pred_mask.astype(np.float64)\n",
            "    pred_mask = np.argmax(pred_mask, axis=2)\n",
            "    \n",
            "    #Add three images to list\n",
            "    images = []\n",
            "    images.append(image)\n",
            "    images.append(mask)\n",
            "    images.append(pred_mask)\n",
            "\n",
            "    #Show and plot all three images\n",
            "    plt.figure(figsize=(30,30))\n",
            "    columns = 5\n",
            "    for i, image in enumerate(images):\n",
            "        image_plot = plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
            "        if i == 0:\n",
            "            label = 'Raw Image {}'.format(num)\n",
            "            image_plot.set_title(label)\n",
            "            result = plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
            "        elif i == 1: \n",
            "            label = 'Ground Truth {}'.format(num)\n",
            "            image_plot.set_title(label)\n",
            "            result = plt.imshow(image)\n",
            "        elif i == 2: \n",
            "            label = 'Predicted Mask {}'.format(num)\n",
            "            image_plot.set_title(label)\n",
            "            result = plt.imshow(image)\n",
            "        pred_results[label] = result"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 884
            },
            "colab_type": "code",
            "id": "QvZxw18y8CFE",
            "outputId": "5f134e7a-27f6-401f-8d2a-02a3c554fec4"
         },
         "outputs": [],
         "source": [
            "#Display dictionary of sample test results\n",
            "pred_results"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {},
            "colab_type": "code",
            "id": "LhbZa7yf8dul"
         },
         "outputs": [],
         "source": [
            "#Pickle sample test results\n",
            "f = open(\"pred_results.pkl\",\"wb\")\n",
            "pickle.dump(pred_results,f)\n",
            "f.close()"
         ]
      }
   ],
   "metadata": {
      "accelerator": "GPU",
      "colab": {
         "collapsed_sections": [],
         "name": "UNetWithEfficientNet.ipynb",
         "provenance": []
      },
      "kernelspec": {
         "display_name": "Python 3.10.4 64-bit",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "name": "python",
         "version": "3.10.4"
      },
      "vscode": {
         "interpreter": {
            "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 0
}
